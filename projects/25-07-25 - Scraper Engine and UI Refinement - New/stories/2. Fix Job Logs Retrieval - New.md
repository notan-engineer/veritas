# User Story 2: Troubleshoot Jobs by Viewing Logs

**Status**: ðŸ†• New  
**Epic**: Overhaul Job Lifecycle & History  
**Priority**: High  
**Estimated Effort**: 2 hours

## User Story

As a **system administrator**, I want to **view job logs directly from the UI** so that I can **troubleshoot failed jobs and understand what happened during processing**.

## Background

The job logs API endpoint currently returns a database error: `{"success":false,"error":"Failed to retrieve job logs from database"}`. This prevents administrators from debugging issues. Logs exist in the `scraping_logs` table but the retrieval query appears to be broken.

## Acceptance Criteria

- [ ] Job logs API endpoint returns data successfully
- [ ] Logs include timestamp, level, message, and additional_data
- [ ] Expand button in jobs table reveals logs
- [ ] Logs are formatted for readability
- [ ] Error messages are descriptive
- [ ] Large log sets are paginated or truncated

## Technical Approach

### 1. Fix Backend API
```typescript
// services/scraper/src/server.ts (or database.ts)
// Fix the query - likely issue with job_id parameter
app.get('/api/jobs/:id/logs', async (req, res) => {
  const { id } = req.params;
  
  // Ensure proper parameterized query
  const query = `
    SELECT 
      timestamp,
      level,
      message,
      additional_data
    FROM scraping_logs
    WHERE job_id = $1
    ORDER BY timestamp ASC
  `;
  
  const result = await db.query(query, [id]);
  res.json({ success: true, logs: result.rows });
});
```

### 2. UI Integration
```typescript
// services/ui/app/scraper/components/dashboard-tab.tsx
// Add expandable row functionality
const [expandedRows, setExpandedRows] = useState<Set<string>>(new Set());

const toggleExpand = async (jobId: string) => {
  if (expandedRows.has(jobId)) {
    setExpandedRows(prev => {
      const next = new Set(prev);
      next.delete(jobId);
      return next;
    });
  } else {
    // Fetch logs
    const response = await fetch(`/api/scraper/jobs/${jobId}/logs`);
    const data = await response.json();
    // Store logs and expand row
  }
};
```

## Implementation Steps

1. **Debug backend log retrieval**
   - Locate the failing endpoint
   - Check SQL query syntax
   - Verify parameter passing
   - Test with known job IDs

2. **Fix query implementation**
   - Correct parameter binding
   - Handle missing logs gracefully
   - Add proper error handling
   - Return structured response

3. **Implement UI log display**
   - Add expand/collapse state
   - Fetch logs on expand
   - Format log display
   - Handle loading states

4. **Polish and optimize**
   - Add log level colors
   - Format timestamps
   - Truncate long messages
   - Consider virtualization for many logs

## Test Scenarios

### Scenario 1: Basic Log Retrieval
1. Run a scraping job
2. Note the job ID
3. Expand job row in table
4. Verify logs appear
5. Check all log fields present

### Scenario 2: Error Handling
1. Try to view logs for non-existent job
2. Verify graceful error message
3. Try with job that has no logs
4. Verify empty state message

### Scenario 3: Large Log Sets
1. Run job that generates many logs
2. Expand to view logs
3. Verify performance is acceptable
4. Check if pagination/truncation works

## Verification Steps

### Pre-Implementation
- [ ] Locate exact file with log retrieval endpoint
- [ ] Verify scraping_logs table structure
- [ ] Check for existing job_id values to test with
- [ ] Understand current error source

### Post-Implementation
- [ ] API returns logs successfully
- [ ] UI displays logs correctly
- [ ] Performance is acceptable
- [ ] Error cases handled gracefully

## Dependencies

- Access to scraper service code
- Understanding of current database schema
- Existing job IDs for testing

## Risks and Mitigations

- **Risk**: Query performance with many logs
  - **Mitigation**: Add LIMIT clause, implement pagination

- **Risk**: Breaking changes to log structure
  - **Mitigation**: Handle missing fields gracefully

- **Risk**: Security - exposing sensitive data
  - **Mitigation**: Sanitize log output, check permissions

## Definition of Done

- [ ] Log API endpoint returns data
- [ ] Logs viewable from UI
- [ ] Error handling implemented
- [ ] Performance acceptable
- [ ] Documentation updated
- [ ] No regressions in existing features